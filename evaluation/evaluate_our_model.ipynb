{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import gensim as gs\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "warnings.filterwarnings('ignore')\n",
    "from transformers import TFBertModel, BertTokenizer, TFBertMainLayer, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_articles = pd.read_csv('../dataset/test_articles_newyork.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_index = pd.read_csv('../dataset/fixed_test_set_newyork.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(ID_goal,ranked_tables_ID):\n",
    "    \n",
    "    accuracy = 0\n",
    "    \n",
    "    for table_ID in ranked_tables_ID:\n",
    "        \n",
    "        if table_ID[0] == ID_goal:\n",
    "    \n",
    "            accuracy = 1\n",
    "            break;\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mrr(ID_goal,ranked_tables_ID):\n",
    "    \n",
    "    accuracy = 0\n",
    "    index_match = 1\n",
    "\n",
    "    for idTable in ranked_tables_ID:\n",
    "        \n",
    "        if idTable[0] == ID_goal:\n",
    "    \n",
    "            accuracy = 1/index_match\n",
    "            break;\n",
    "        \n",
    "        index_match = index_match + 1\n",
    "   \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_model = gs.models.FastText.load('../train_embedding_models/fasttext_embedding_50d_all_signals')\n",
    "embedding_model = gs.models.FastText.load_fasttext_format('../pre_trained_models/cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PAD_TITLE = 30\n",
    "\n",
    "def sequence_padding_title(X_DIM, value):\n",
    "    \n",
    "    value_padding = np.pad(value, ((0,MAX_PAD_TITLE - X_DIM),(0,0)), 'constant')\n",
    "    \n",
    "    return value_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_title(value):\n",
    "\n",
    "    value = tknzr.tokenize(str(value))\n",
    "    \n",
    "    if len(value) < MAX_PAD_TITLE:\n",
    "        \n",
    "        embedding = embedding_model.wv[value]\n",
    "        embedding = embedding.astype('float16')\n",
    "        \n",
    "        padding_embedding = sequence_padding_title(embedding.shape[0],embedding)\n",
    "        \n",
    "        return padding_embedding\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        embedding = embedding_model.wv[value[0:MAX_PAD_TITLE]]\n",
    "        embedding = embedding.astype('float16')\n",
    "        \n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PAD_MAIN_PASSAGE = 55\n",
    "\n",
    "def sequence_padding_main_passage(X_DIM, value):\n",
    "    \n",
    "    value_padding = np.pad(value, ((0,MAX_PAD_MAIN_PASSAGE - X_DIM),(0,0)), 'constant')\n",
    "    \n",
    "    return value_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_main_passage(value):\n",
    "\n",
    "    value = tknzr.tokenize(str(value))\n",
    "    \n",
    "    if len(value) < MAX_PAD_MAIN_PASSAGE:\n",
    "        \n",
    "        embedding = embedding_model.wv[value]\n",
    "        embedding = embedding.astype('float16')\n",
    "        \n",
    "        padding_embedding = sequence_padding_main_passage(embedding.shape[0],embedding)\n",
    "        \n",
    "        return padding_embedding\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        embedding = embedding_model.wv[value[0:MAX_PAD_MAIN_PASSAGE]]\n",
    "        embedding = embedding.astype('float16')\n",
    "        \n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models = []\n",
    "evaluate_models.append('bert_based_models/model_ablation/model_ablation05_02_0.9847.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_articles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_topk = [1,5,10,20,50]\n",
    "\n",
    "for i in range(0,len(evaluate_models)):\n",
    "\n",
    "    result = []\n",
    "\n",
    "    print(\"current_model: \"+ evaluate_models[i])\n",
    "\n",
    "    #loading the current model\n",
    "    ranking_model = tf.keras.models.load_model(evaluate_models[i])\n",
    "\n",
    "    #evaluating each topk value\n",
    "    for TOP_K in evaluate_topk:\n",
    "\n",
    "        accuracy = []\n",
    "        mrr = []\n",
    "\n",
    "        for i, row in tqdm(test_articles.iterrows()):\n",
    "\n",
    "            #current article values\n",
    "            #article_url = row['article_url']\n",
    "            article_ID = row['article_key_match']\n",
    "            article_title_text = row['article_title']\n",
    "            article_main_passage_text = str(row['article_meta_description'])\n",
    "            article_keywords_text = str(row['article_keywords'])\n",
    "\n",
    "            #embedding and model variables\n",
    "            article_title = []\n",
    "            article_main_passage = []\n",
    "            article_keywords = []\n",
    "            table_title = []\n",
    "            table_main_passage = []\n",
    "            table_keywords = []\n",
    "            test_title_ids = []\n",
    "            test_title_mask = []\n",
    "            test_title_seg = []\n",
    "            ranked_tables_model = []\n",
    "\n",
    "            #return index\n",
    "            return_index = fixed_index.loc[fixed_index['label_index'] == row['article_key_match']]\n",
    "\n",
    "            #creating embedding \n",
    "            for i, row in return_index.iterrows():\n",
    "\n",
    "                #bert\n",
    "                return_tokenizer1 = bert_tokenizer.encode_plus(\n",
    "                  article_title_text+\" \"+article_main_passage_text+\" \"+article_keywords_text,\n",
    "                    row['table_page_title']+\" \"+str(row['table_page_main_passage'])+\" \"+str(row['table_page_keywords']),\n",
    "                  max_length=MAX_TOKENS,\n",
    "                  add_special_tokens=True,\n",
    "                  return_token_type_ids=True,\n",
    "                  pad_to_max_length=True,\n",
    "                  return_attention_mask=True,\n",
    "                )\n",
    "\n",
    "                #bert\n",
    "                test_title_ids.append(return_tokenizer1['input_ids'])\n",
    "                test_title_mask.append(return_tokenizer1['attention_mask'])\n",
    "                test_title_seg.append(return_tokenizer1['token_type_ids'])  \n",
    "                \n",
    "                #fasttext embedding\n",
    "                article_title_embedding = create_embedding_title(article_title_text)\n",
    "                article_main_passage_embedding = create_embedding_main_passage(article_main_passage_text)\n",
    "                article_keywords_embedding = create_embedding_title(article_keywords_text)\n",
    "                \n",
    "                table_title_embedding = create_embedding_title(row['table_page_title'])\n",
    "                table_main_passage_embedding = create_embedding_main_passage(str(row['table_page_main_passage']))\n",
    "                table_keywords_embedding = create_embedding_title(row['table_page_keywords'])\n",
    "\n",
    "                article_title.append(article_title_embedding)\n",
    "                article_main_passage.append(article_main_passage_embedding)\n",
    "                article_keywords.append(article_keywords_embedding)\n",
    "                table_title.append(table_title_embedding)\n",
    "                table_main_passage.append(table_main_passage_embedding)\n",
    "                table_keywords.append(table_keywords_embedding)\n",
    "                \n",
    "                    \n",
    "            #bert\n",
    "            test_title_ids = np.array(test_title_ids)\n",
    "            test_title_mask = np.array(test_title_mask)\n",
    "            test_title_seg = np.array(test_title_seg)\n",
    "            \n",
    "            #fasttext\n",
    "            article_title = np.array(article_title, dtype='float16')\n",
    "            article_main_passage = np.array(article_main_passage, dtype='float16')\n",
    "            article_keywords = np.array(article_keywords, dtype='float16')\n",
    "            \n",
    "            table_title = np.array(table_title, dtype='float16')\n",
    "            table_main_passage = np.array(table_main_passage, dtype='float16')\n",
    "            table_keywords = np.array(table_keywords, dtype='float16')\n",
    "           \n",
    "            table_ranking_model = ranking_model.predict([test_title_ids,test_title_mask,test_title_seg, article_title, article_main_passage, article_keywords, table_title, table_main_passage, table_keywords])\n",
    "\n",
    "            #creating the final dataframe\n",
    "            for i in range(0,len(table_ranking_model)):\n",
    "\n",
    "                ranked_tables_model.append([return_index.iloc[i]['table_page_id'],return_index.iloc[i]['table_page_title'],table_ranking_model[i][0]]) \n",
    "\n",
    "            data_frame = pd.DataFrame(ranked_tables_model, columns = ['table_ID', 'table_title','table_ranking']) \n",
    "            data_frame_sorting = data_frame.sort_values('table_ranking', ascending=False)  \n",
    "\n",
    "            selected_top = data_frame_sorting.head(TOP_K)\n",
    "#             min_score = selected_top['table_ranking'].min()\n",
    "#             draw_tables_socres = data_frame_sorting[data_frame_sorting['table_ranking'] >= min_score]\n",
    "            final_ranked_tables = selected_top.iloc[:,0:1].values\n",
    "            \n",
    "#             print(\"\")\n",
    "#             print(\"query:\"+ article_url)\n",
    "#             print(\"\")\n",
    "#             print(\"match:\" +article_ID)\n",
    "#             print(\"\")\n",
    "#             print(selected_top)\n",
    "\n",
    "            #getting topk accuracy\n",
    "            accuracy.append(get_accuracy(article_ID, final_ranked_tables))\n",
    "\n",
    "            #testing mean reciprocal rank at k = 50\n",
    "            if TOP_K == 50:\n",
    "\n",
    "                mrr.append(get_mrr(article_ID, final_ranked_tables))\n",
    "\n",
    "        result.append([\"Acc@\"+str(TOP_K),str(round(np.mean(accuracy),4))])\n",
    "\n",
    "    print(\"\")\n",
    "    print(result[0])\n",
    "    print(result[1])\n",
    "    print(result[2])\n",
    "    print(result[3])\n",
    "    print(result[4])\n",
    "    print(\"MRR: \"+str(round(np.mean(mrr),4)) )\n",
    "    print(mrr)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
